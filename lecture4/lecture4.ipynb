{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "## Bayesian information theory: Lecture 4\n",
    "\n",
    "<span style=\"color:red\"> *Warning not complete yet!*</span>\n",
    "\n",
    "*This jupyter notebook is part of a [collection of notebooks](../index.ipynb) on various topics of Bayesian Information Theory. Please direct questions and suggestions to [j.jasche@tum.de](mailto:j.jasche@tum.de).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating integrals\n",
    "$\\newcommand{\\vect}[1]{\\mathbf{#1}}$\n",
    "\n",
    "Bayesian statistics is numerically challenging because we often have to evaluate integrals of the form:<br/><br/>\n",
    "\n",
    "<center> $I =   \\frac{\\int \\mathrm{d}\\vect{x}\\,\\pi(\\vect{x})\\,  f(\\vect{x})}{\\int \\mathrm{d}\\vect{x}\\,\\pi(\\vect{x}) } = \\langle f \\rangle_{\\pi}  $ </center> <br/><br/>\n",
    "\n",
    "\n",
    "<p>** Lemma  **:</p>\n",
    "<blockquote>\n",
    "<p>  Let the harmonic mean:<br/><br/>\n",
    "      <center>$ I_N = \\frac{1}{N} \\sum_i f(\\vect{x}_i)$</center><br/><br/>\n",
    "    of an ensemble of points $\\{\\vect{x}_1, ... ,\\vect{x}_N \\}$ be an estimator of the integral $I$. Then\n",
    "    $I_N$ is an unbiased estimator of the integral $I$ if and only if the $\\{\\vect{x}_1, ... ,\\vect{x}_N \\}$ are distributed like the target distribution $\\pi(\\vect{x})$, that is the $\\vect{x}_i$ are random variates of $\\pi(\\vect{x}_i)$:<br/><br/>\n",
    "     <center>$ \\vect{x}_i \\curvearrowleft \\pi(\\vect{x}_i)$</center></p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "<p>** Proof **:</p>\n",
    "<blockquote>\n",
    "<p>  Assume $\\vect{x}_i \\curvearrowleft \\omega(\\vect{x}_i)$ then:<br/><br/>\n",
    "      <center>$\\begin{eqnarray} \\langle I_N \\rangle_{\\omega}  &=& \\frac{1}{N} \\sum_i  \\langle f\\left(\\vect{x}_i\\right) \\rangle_{\\omega}\\\\ \\nonumber  &=& \\frac{1}{N} \\sum_i  \\frac{\\int \\mathrm{d}\\vect{x_i}\\,\\pi(\\vect{x_i})\\,  f(\\vect{x_i})}{\\int \\mathrm{d}\\vect{x_i}\\,\\pi(\\vect{x_i}) }\\nonumber \\\\ &=& \\frac{1}{N} \\sum_i  \\langle f \\rangle_{\\omega} \\nonumber \\\\ &=& \\langle f \\rangle_{\\omega}  \\end{eqnarray}$</center><br/><br/>\n",
    "Then $\\langle I_N \\rangle_{\\omega} = I $  only if:<br/><br/>\n",
    "    <center>$ \\omega(\\vect{x}_i) = \\pi(\\vect{x}_i)$</center></p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "<p>** Lemma  **:</p>\n",
    "<blockquote>\n",
    "<p>  The variance of $I_N$ is independent of dimension and converges to zero for large ensemble sizes $N$</p>\n",
    "</blockquote>\n",
    "\n",
    "<p>** Proof **:</p>\n",
    "<blockquote>\n",
    "<p>   <center>$\\begin{eqnarray}\\langle \\left[ I_N - \\langle I_N \\rangle_{\\pi}\\right]^2\\rangle_{\\pi}   &=& \\left \\langle \\left[ \\frac{1}{N} \\sum_i f(\\vect{x}_i) - \\langle f \\rangle_{\\pi}\\right]^2\\right\\rangle_{\\pi}\\\\ \\nonumber  &=& \\left \\langle \\left[ \\frac{1}{N} \\sum_i \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)\\right]^2\\right\\rangle_{\\pi}\\nonumber \\\\ &=& \\frac{1}{N^2} \\left \\langle \\sum_i\\sum_j \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)\\left( f(\\vect{x}_j) - \\langle f \\rangle_{\\pi} \\right)\\right\\rangle_{\\pi} \\nonumber \\\\ &=& \\frac{1}{N^2} \\left \\langle \\sum_i\\sum_j \\delta^K_{ij} \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)^2 +  2  \\sum_i\\sum_{j>i} \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)\\left( f(\\vect{x}_j) - \\langle f \\rangle_{\\pi} \\right) \\right\\rangle_{\\pi}  \\end{eqnarray}$</center><br/><br/>\n",
    "Now:<br/><br/>\n",
    "    \n",
    "<center>$\\begin{eqnarray}\\left \\langle \\sum_i\\sum_{j>i} \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)\\left( f(\\vect{x}_j) - \\langle f \\rangle_{\\pi} \\right) \\right\\rangle_{\\pi} &=&  \\sum_i \\left \\langle \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)\\right\\rangle_{\\pi} \\sum_{j>i}\\left( f(\\vect{x}_j) - \\langle f \\rangle_{\\pi} \\right) \\nonumber \\\\ && + \\sum_i  \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right) \\sum_{j>i} \\left \\langle \\left( f(\\vect{x}_j) - \\langle f \\rangle_{\\pi} \\right) \\right\\rangle_{\\pi}\\nonumber \\\\ &=& 0  \\end{eqnarray}$</center><br/><br/>\n",
    "Then:\n",
    "<center>$\\begin{eqnarray}\\langle \\left[ I_N - \\langle I_N \\rangle_{\\pi}\\right]^2\\rangle_{\\pi} &=& \\frac{1}{N^2} \\left \\langle \\sum_i\\sum_j \\delta^K_{ij} \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)^2  \\right\\rangle_{\\pi} \\nonumber \\\\ &=& \\frac{1}{N^2}  \\sum_i \\left \\langle \\left( f(\\vect{x}_i) - \\langle f \\rangle_{\\pi} \\right)^2  \\right\\rangle_{\\pi} \\nonumber \\\\ &=& \\frac{1}{N^2}  \\sum_i \\sigma^2_f \\nonumber \\\\ &=& \\frac{\\sigma^2_f}{N}  \\end{eqnarray}$</center><br/><br/>\n",
    "That is, the estimator variance is independent of dimension and the error decreases to zero for large $N$.    \n",
    "</blockquote>\n",
    "\n",
    "\n",
    "# Generation of random variates\n",
    "Given the previous discussion, we can find unbiased solutions to any Bayesian integration problem if we can generate an ensemble of random realizations $\\{\\vect{x}_1, ... ,\\vect{x}_N \\}$ of the target distribution $\\pi(\\vect{x})$, such that:<br/><br/>\n",
    "<center>$\\begin{eqnarray} \\pi(\\vect{x}) \\approx \\frac{1}{N} \\sum_i \\delta^D(\\vect{x}-\\vect{x}_i) \\end{eqnarray}$</center><br/><br/>\n",
    "That is the density of points $\\{\\vect{x}_1, ... ,\\vect{x}_N \\}$ approximates the target density.\n",
    "\n",
    "\n",
    "##Direct sampling method\n",
    "\n",
    "Let: <center>$ F(x)=\\frac{\\int_{-infty}^{x} \\mathrm{d}\\vect{y}\\,\\pi(\\vect{y})\\,  }{\\int\\int_{-infty}^{\\infty} \\mathrm{d}\\vect{y}\\,\\pi(\\vect{y}) } $</center><br/><br/>\n",
    "be the cumulative distribution of $\\pi(\\vect{x})$. Then $F(x) \\in [0,1]$\n",
    "\n",
    "<p>** Procedure **: </p>\n",
    "<blockquote>\n",
    "<p> 1) Draw a uniform random variate $u$ from $U[0,1]$\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) Calculate $x'=F^{-1}(u)$</p>\n",
    "</blockquote>\n",
    "\n",
    "Then $x'$ is a random variate of $\\pi(x)$.\n",
    "\n",
    "<p>** Proof **: Cange of coordinates</p>\n",
    "<blockquote>\n",
    "<p> Let $u=F(x)$ then conservation of probability requires:<br/><br/>\n",
    "      <center>$\\pi(x) \\mathrm{d}x = U(u) \\mathrm{d}u $, </center> <br/><br/>\n",
    "      where the uniform distribution $U(u)=1$ for all $u \\in [0,1]$. Then:<br/><br/>\n",
    "      <center>$\\begin{eqnarray}\\pi(x)  &=& U(F(x)) \\frac{\\mathrm{d}u}{\\mathrm{d}u} \\nonumber \\\\ &=& \\frac{\\mathrm{d}F(x)}{\\mathrm{d}u} \\nonumber \\\\ &=& \\pi(x)   \\end{eqnarray}$, </center></p> <br/><br/>   \n",
    "</blockquote>\n",
    "This inverse transform sampling technique is at the core of many basic sampling algorithm. However it does not generalize easily to multivariate problems.\n",
    "\n",
    "\n",
    "# Markov Chain Monte Carlo\n",
    "\n",
    "We would like to find a discrete time stochastic process that automatically generates a sequence of random variates $\\{x_1, ... ,x_n, ... \\}$ distributed like the target distribution $\\pi(x)$.<br/><br/> \n",
    "\n",
    "<p>** Definition  **: Markov process</p>\n",
    "<blockquote>\n",
    "<p>  A Markov chain on the domain $\\Omega$ is a stochastic process with $X_1, ... ,X_n, ... \\}$ with each $X_i \\in \\Omega$ such that:<br/><br/>\n",
    "    \n",
    "<center>$K(X_{n+1}=x'|X_{n}=x,X_{n-1}=x_{n-1},...,X_{0}=x_{0})=K(X_{n+1}=x'|X_{n}=x) =: T(x'|x) $, </center><br/><br/> \n",
    "\n",
    "This means the criterion to jump from $x$ to $x'$ depends only on the current position $x$ but not on the previos history of jumps. We also require the trasition kernel $T(x'|x)$ to be a probability, that is:<br/><br/> \n",
    "\n",
    "<center>$T(x'|x) \\geq 0 $ for all $x,x' \\in \\Omega $, </center><br/><br/>\n",
    "\n",
    "and <br/><br/>\n",
    "\n",
    "<center>$\\int \\mathrm{d}x' \\, T(x'|x) = 1 $ for all $x,x' \\in \\Omega $, </center><br/><br/>\n",
    "</p>   \n",
    "</blockquote>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now suppose the initial positions $x$  are distributed like $\\omega(x)$ then after one transition step we obtain the new distribution $\\omega'(x')$ as: <br/><br/>\n",
    "\n",
    "<center>$ \\omega'(x') =\\int \\mathrm{d}x \\, \\omega(x)\\, T(x'|x)$. </center><br/><br/>\n",
    "\n",
    "We require the Markov process to generate stationary distributions, that is, after a transition the new positions $x'$ should be distributed according to the same distribution prior to the jump. More specifically we require this stationary distribution to be the desired target distribution:<br/><br/>\n",
    "\n",
    "<center>$ \\omega'(x) =\\omega(x)= \\pi(x)$. </center><br/><br/>\n",
    "\n",
    "More specifically:<br/><br/>\n",
    "\n",
    "<center>$ \\pi(x') =\\int \\mathrm{d}x \\, \\pi(x)\\, T(x'|x)$. </center><br/><br/>\n",
    "\n",
    "\n",
    "<p>** Lemma  **:</p>\n",
    "<blockquote>\n",
    "<p>  A homogeneous Markov Hain, satisfying detailed balance, has the target distribution $\\pi(x)$ as its stationary distribution:<br/><br/>\n",
    "<center>$ \\pi(x') T(x|x') =\\pi(x) T(x'|x)$. </center><br/><br/>\n",
    "That is, it is equally likely to jump from $x$ to $x'$ as it is to jump from $x'$ to $x$. </p>\n",
    "</blockquote>\n",
    "\n",
    "<p>** Proof **:</p>\n",
    "<blockquote>\n",
    "<p>   <center>$\\begin{eqnarray} \\int \\mathrm{d}x \\pi(x) T(x'|x) &=& \\int \\mathrm{d}x \\pi(x') T(x|x') \\nonumber \\\\\n",
    "&=& \\pi(x') \\int \\mathrm{d}x  T(x|x') \\nonumber \\\\\n",
    "&=& \\pi(x')  \\nonumber \\\\\n",
    "\\end{eqnarray}$</center></p>\n",
    "    \n",
    "    \n",
    "    \n",
    "A large fraction of the work in numarical Bayesian approaches is therefore concerned with finding suitable transition kernels $T(x'|x)$ that satisfy detailed balance.    \n",
    "\n",
    "\n",
    "# The Metropolis Hastings Transition\n",
    "\n",
    "Let $T(x'|x)$  be a transition kernal that induces a Markov chain. If $T(x'|x)$ does not satisfy detailed balance we may encounter the following situation: <br/><br/>\n",
    "\n",
    "<center>$ \\pi(x') T(x|x')  < \\pi(x) T(x'|x)$. </center><br/><br/>\n",
    "\n",
    "That is jumps from $x$ to $x'$ are on average more likely than jumps from $x'$ to $x$. In order to re-balnace the transitions we could introduce a probability $\\alpha(x'|x)<1$ and modify the transition kernel as:<br/><br/>\n",
    "\n",
    "<center>$ T_{\\mathrm{MH}}(x'|x) = T(x'|x) \\alpha(x'|x) $. </center><br/><br/>\n",
    "\n",
    "Note, that since transitions $x$ to $x'$ are too frequent the probability for transitions from $x'$ to $x$ needs to be maximal, that is $\\alpha(x|x')=1$. Then:<br/><br/>\n",
    "\n",
    "\n",
    "<center>$ \\begin{eqnarray}  \\pi(x') T_{\\mathrm{MH}}(x|x')  &=& \\pi(x) T_{\\mathrm{MH}}(x'|x)\\nonumber \\\\  \\pi(x') T(x|x')\\alpha(x|x')  &=& \\pi(x) T(x'|x)\\alpha(x'|x)\\nonumber \\\\  \\pi(x') T(x|x') & =& \\pi(x) T(x'|x)\\alpha(x'|x)\\end{eqnarray}$. </center><br/><br/>\n",
    "\n",
    "Via algebraic re-arrangement we obtain:<br/><br/>\n",
    "\n",
    "<center>$ \\alpha(x'|x) = \\frac{\\pi(x') T(x|x')}{\\pi(x) T(x'|x)} < 1  $ and $\\alpha(x|x')=1$. </center><br/><br/>\n",
    "\n",
    "For the reverse problem:<br/><br/>\n",
    "\n",
    "<center>$ \\pi(x') T(x|x')  > \\pi(x) T(x'|x)$. </center><br/><br/>\n",
    "\n",
    "We obtain:<br/><br/>\n",
    "\n",
    "<center>$ \\alpha(x|x') = \\frac{\\pi(x) T(x'|x)}{\\pi(x') T(x|x')} < 1  $ and $\\alpha(x'|x)=1$. </center><br/><br/>\n",
    "\n",
    "Since then:<br/><br/>\n",
    "\n",
    "<center>$ \\frac{\\pi(x') T(x|x')}{\\pi(x) T(x'|x)} >1  $ </center><br/><br/>\n",
    "\n",
    "we can generalize:<br/><br/>\n",
    "\n",
    "<center>$ \\alpha(x'|x) =\\mathrm{min}\\left[1, \\frac{\\pi(x') T(x|x')}{\\pi(x) T(x'|x)}\\right]$. </center><br/><br/>\n",
    "\n",
    "The full Metropolis Hastings transition Kernel also needs to include the possibility to stay at the current position.\n",
    "The Kernel is then given by:<br/><br/>\n",
    "\n",
    "<center>$ T_{\\mathrm{MH}}(x'|x) = T(x'|x) \\alpha(x'|x) +\\left[ 1 - \\int \\mathrm{d}y T(y|x) \\, \\alpha(y|x)\\right]\\, \\delta^D(x'-x) $. </center><br/><br/>\n",
    "\n",
    "\n",
    "<p>** Features **: </p>\n",
    "<blockquote>\n",
    "<p> 1) Independence of normalization</p>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) Can use various simple transition kernels $T(x'|x)$ to generate stationary distributions </p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "\n",
    "<p>** Procedure **: </p>\n",
    "<blockquote>\n",
    "<p> 1) Draw  $x^*$ from the transition distribution $T(x'|x)$\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) Draw a uniform random variate $u$ from $U[0,1]$\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) set  the new position as $x'=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  x^* \\,\\,\\,\\,\\,\\,\\,\\, \\mathrm{if} \\, u \\leq \\mathrm{min}\\left[1, \\frac{\\pi(x') T(x|x')}{\\pi(x) T(x'|x)}\\right] \\\\\n",
    "                  x \\,\\,\\,\\,\\,\\,\\,\\, \\mathrm{else}\n",
    "                \\end{array}\n",
    "              \\right. $</p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "# Hamiltonian Monte Carlo Sampling\n",
    "\n",
    "The Hamiltonian Monte Carlo sampler is a very efficient Markov transition generator. Over the past years the Hamiltonian sampler has become a major tool in Bayesian data analysis. It exploits concepts of classical mechanics to overcome the random walk behavior of traditional MCMC aprroaches and provide very efficient explorations of high dimensional parameter spaces.\n",
    "\n",
    "Let:<br/><br/>\n",
    "\n",
    "<center>$ \\Psi(\\vect{x}) = -\\mathrm{ln}(\\pi(\\vect{x}))$. </center><br/><br/>\n",
    "\n",
    "Then we may introduce auxiliary parameter $\\vect{p}$ such that:\n",
    "\n",
    "<center>$ H(\\vect{x},\\vect{p})=\\frac{1}{2} \\sum_{ij} p_i M^{-1}_{ij} p_j + \\Psi(\\vect{x}) $, </center><br/><br/>\n",
    "\n",
    "with the covariance matrix $M_{ij}$ being called the mass matrix. Then $H(\\vect{x},\\vect{p})$ has all the properties of a Hamiltonian of classical mechanics.\n",
    "\n",
    "<p>** Lemma  **:</p>\n",
    "<blockquote>\n",
    "<p>  Augmenting the parameter space from $\\vect{x}$ to $\\vect{x},\\vect{p}$ leaves the target distribution $\\pi(x)$ invariant when marginalizing over $\\vect{p}$.</p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "<p>** Proof **:</p>\n",
    "<blockquote>\n",
    "<p>   <center>$\\begin{eqnarray} \\pi(\\vect{x},\\vect{p}) &\\propto& \\mathrm{e}^{-H(\\vect{x},\\vect{p})}\\nonumber \\\\\n",
    "&=& \\mathrm{e}^{-\\frac{1}{2} \\sum_{ij} p_i M^{-1}_{ij} p_j - \\Psi(\\vect{x})  }\\nonumber \\\\\n",
    "&=&\\mathrm{e}^{-\\frac{1}{2} \\sum_{ij} p_i M^{-1}_{ij} p_j} \\, \\pi(\\vect{x}) \\nonumber \\\\\n",
    "\\end{eqnarray}$</center>\n",
    "Therefore: <br/><br/>   \n",
    "<center>$ \\int \\mathrm{d}\\vect{p }\\pi(\\vect{x},\\vect{p}) \\propto \\pi(\\vect{x}) \\int \\mathrm{d}\\vect{p } \\, \\mathrm{e}^{-\\frac{1}{2} \\sum_{ij} p_i M^{-1}_{ij} p_j} \\propto \\pi(\\vect{x})    $. </center><br/><br/>\n",
    "\n",
    "Since the distribution factorizes in $\\vect{x}$ and $\\vect{p}$ introduction of auxiliary momenta  $\\vect{p}$ does not affect the distribution of the $\\vect{x}$.</p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p>** Procedure **: </p>\n",
    "<blockquote>\n",
    "<p> 1) Draw  $p'$ from the normal distribution $\\frac{\\mathrm{e}^{-\\frac{1}{2} \\sum_{ij} p_i M^{-1}_{ij} p_j}}{\\sqrt{\\mathrm{det}(2\\pi M)}}$\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) Draw a uniform random variate $u$ from $U[0,1]$\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) Integrate Hamiltonian equations of Motion:<br/><br/>\n",
    "    <center>$\\begin{eqnarray} \\frac{\\mathrm{d}x_i}{\\mathrm{d}t} &=& \\frac{\\partial H}{\\partial p_i} = \\sum_j M^{-1}_{ij} \\nonumber \\\\ \\frac{\\mathrm{d}p_i}{\\mathrm{d}t} &=& -\\frac{\\partial H}{\\partial x_i} = -\\frac{\\partial \\Psi}{\\partial x_i}\\end{eqnarray} $ </center><br/><br/>\n",
    "for some amount of pseudo time $\\tau$ and subject to initial conditions $\\vect{x}$ and $\\vect{p}$.    </p>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 3) Accept new states $\\vect{x}'=\\vect{x}(\\tau)$ and $\\vect{p}'=\\vect{p}(\\tau)$ as new samples with the MH acceptance probability:<br/><br/>\n",
    "    <center>$\\begin{eqnarray} \\mathrm{min}\\left[1, \\mathrm{e}^{-\\left(H(\\vect{x}',\\vect{p}') - H(\\vect{x},\\vect{p}) \\right)}\\right]\\end{eqnarray} $ </center> </p>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "Since Hamiltonian Dynamics conserves the Hamiltonian the acceptance rate is unity.\n",
    "\n",
    "<p>** Advantages **: </p>\n",
    "<blockquote>\n",
    "<p> 1) HMC exploits conserved quantities to have unit acceptance rate</p>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<p> 2) HMC uses gradients to efficiently explore high-d parameter spaces. </p>\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
